<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Project Starline A high-fidelity telepresence system</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Project Starline A high-fidelity telepresence system"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://ankbzpx.github.io/my-personal-knowledge-cache/notes/e9ow9c6apojiqfio5e5ceht/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="7/14/2022"/><meta property="article:modified_time" content="7/15/2022"/><link rel="canonical" href="https://ankbzpx.github.io/my-personal-knowledge-cache/notes/e9ow9c6apojiqfio5e5ceht/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/my-personal-knowledge-cache/_next/static/css/6db750d8aae1efab.css" as="style"/><link rel="stylesheet" href="/my-personal-knowledge-cache/_next/static/css/6db750d8aae1efab.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/my-personal-knowledge-cache/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/my-personal-knowledge-cache/_next/static/chunks/webpack-14fc00b0a180680f.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/chunks/main-ced06fae44febf7d.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/chunks/pages/_app-7f0c0a28af6ee1f5.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/chunks/155-3a6c02d7e042edb7.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/chunks/373-9c38fabb487d5920.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/chunks/pages/notes/%5Bid%5D-b20175c77adb354a.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/ihOclfcI71GY0CxNfF2GS/_buildManifest.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/ihOclfcI71GY0CxNfF2GS/_ssgManifest.js" defer=""></script><script src="/my-personal-knowledge-cache/_next/static/ihOclfcI71GY0CxNfF2GS/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout site-layout" style="margin-top:64px"><section class="ant-layout site-layout" style="flex-direction:row"><section class="ant-layout site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></section><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="project-starline-a-high-fidelity-telepresence-system"><a aria-hidden="true" class="anchor-heading" href="#project-starline-a-high-fidelity-telepresence-system"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Project Starline A high-fidelity telepresence system</h1>
<blockquote>
<p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/3696afb4c1cccbe0876a9fedd1586f0f9c84f737.pdf">https://storage.googleapis.com/pub-tools-public-publication-data/pdf/3696afb4c1cccbe0876a9fedd1586f0f9c84f737.pdf</a></p>
</blockquote>
<h2 id="hci"><a aria-hidden="true" class="anchor-heading" href="#hci"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>HCI</h2>
<p>VR, AR: hard to capture under headset, insufficient pixel density and viewport</p>
<p>autostereoscopic display (65-inch 8K 33.1M pixel 60Hz, 1.25m eye-to-eye distance, 45 pixel per degree)</p>
<ul>
<li>Face near display panel (reduce disparity)</li>
<li>Place middle wall to block bottom of display (reduce depth conflicts)</li>
<li>Matching remote to local transform for both sides (ensure mutual eye contact)</li>
</ul>
<h3 id="todo"><a aria-hidden="true" class="anchor-heading" href="#todo"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>TODO</h3>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled> crosstalk</li>
<li class="task-list-item"><input type="checkbox" disabled> vergence-accommodation conflict</li>
<li class="task-list-item"><input type="checkbox" disabled> disparity</li>
<li class="task-list-item"><input type="checkbox" disabled> depth conflicts</li>
<li class="task-list-item"><input type="checkbox" disabled> mutual eye contact</li>
</ul>
<h2 id="setup"><a aria-hidden="true" class="anchor-heading" href="#setup"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Setup</h2>
<ul>
<li>4 tracking cameras (2 above, 2 side): localized eyes, ears, mouth, 120Hz</li>
<li>3 depth (stereo) camera: depth stream, 180Hz -> image-based depth fusion</li>
<li>4 color camera: color stream, 60Hz -> Normal based texture blending</li>
</ul>
<h3 id="todo-1"><a aria-hidden="true" class="anchor-heading" href="#todo-1"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>TODO</h3>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled> HRTF (head-related transfer function)</li>
<li class="task-list-item"><input type="checkbox" disabled> Normal based texture blending</li>
</ul>
<h2 id="implementation"><a aria-hidden="true" class="anchor-heading" href="#implementation"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Implementation</h2>
<h3 id="lighting"><a aria-hidden="true" class="anchor-heading" href="#lighting"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Lighting</h3>
<ul>
<li>IBL (Image-based rendering), no illumination or reflectance</li>
<li>Interpolates textures from 4 color cameras</li>
<li>Non-Lambertian reflectance rander incorrectly under non-diffuse lighting (mitigated using soft lighting)</li>
<li>illumination nonuniformity (stronger intensities for display unit near wall)</li>
</ul>
<h3 id="calibration"><a aria-hidden="true" class="anchor-heading" href="#calibration"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Calibration</h3>
<ul>
<li>Minimizing reprojection error over planar targets</li>
<li>Color calibration to Illuminant D65 (gain, color correction matrix, gamma)</li>
</ul>
<h3 id="capture"><a aria-hidden="true" class="anchor-heading" href="#capture"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Capture</h3>
<ul>
<li>Capture sensor placed at periphery of the display, large parallax</li>
<li>Near-infrared (NIR) global shutter image sensors</li>
<li>Customized depth sensor with near depth continuities</li>
<li>3 types of NIR illumination (NIR bounce light, NIR spot light, illuminate back wall)</li>
</ul>
<h3 id="3d-face-tracking"><a aria-hidden="true" class="anchor-heading" href="#3d-face-tracking"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>3D Face Tracking</h3>
<ul>
<li>Eye location -> stereo rendering</li>
<li>Mouth &#x26; ear location -> spatial audio rendering + crosstalk cancellation</li>
<li>34 facial landmarks, determine 5 2D features (eyes, mouth, ears) and triangulated into 3D</li>
<li>Latency causes crosstalk, mitigated by extrapolation + double exponential smoothing + hysteresis filter</li>
</ul>
<h3 id="compression-and-transmission"><a aria-hidden="true" class="anchor-heading" href="#compression-and-transmission"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Compression and transmission</h3>
<ul>
<li>Transmit color (8 bit) and depth (10 bit) images via video compression (NVENC/NVDEC unit, H.256 codec, YUV420 chroma subsampling)</li>
<li>Clamp depth to reduce quantization artifacts</li>
<li>Transmit via WebRTC</li>
</ul>
<h3 id="rendering"><a aria-hidden="true" class="anchor-heading" href="#rendering"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Rendering</h3>
<ul>
<li>Compute shadow map from color cameras by raycasting on input depth map</li>
<li>Compute user view output depth maps by raycasting on input depth map</li>
<li>Use shadow map to weighted color blend output depth map</li>
</ul>
<h4 id="traditional-surface-fusion"><a aria-hidden="true" class="anchor-heading" href="#traditional-surface-fusion"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Traditional Surface fusion</h4>
<ul>
<li>Fuse depth view into <a href="/my-personal-knowledge-cache/notes/r8y2bovxrlx6vkhn7my8e0m">TSDF</a> as volumetric grid, weighting depth pixel based on depth gradient</li>
<li>March along rays into precomputed voxel grid, find root (iso surface)</li>
</ul>
<h4 id="novel-raycast-approach"><a aria-hidden="true" class="anchor-heading" href="#novel-raycast-approach"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Novel raycast approach</h4>
<ul>
<li>Rasterizing input depth view to low-res output view, find lower/upper bound of distance along the ray using 2D min/max filter, dilate it with small margin</li>
<li>For any point on user view ray, for each depth images, transform point to depth camera view coordinate, sample depth and fusion weight</li>
<li>Fusion weight is inverse proportional to depth standard deviation over 7x7 pixel neighbourhood (0 if point is outside viewport)</li>
</ul>
<h4 id="weighted-color-blending"><a aria-hidden="true" class="anchor-heading" href="#weighted-color-blending"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Weighted color blending</h4>
<ul>
<li>Compute partial visibility using percentage close filter on shadow map</li>
<li>Modulate blend weight by squared cosine of angle between surface normal and camera vector (?)</li>
<li>Adaptively blur composite image along depth discontinuities (Edge blending)</li>
</ul>
<h3 id="audio"><a aria-hidden="true" class="anchor-heading" href="#audio"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Audio</h3>
<p>[skip for now]</p>
<h3 id="todo-2"><a aria-hidden="true" class="anchor-heading" href="#todo-2"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>TODO</h3>
<ul class="contains-task-list">
<li class="task-list-item"><input type="checkbox" disabled> Non-Lambertian reflectance</li>
<li class="task-list-item"><input type="checkbox" disabled> Non-diffuse lighting</li>
<li class="task-list-item"><input type="checkbox" disabled> Lighting ratio</li>
<li class="task-list-item"><input type="checkbox" disabled> Non-planar warp</li>
<li class="task-list-item"><input type="checkbox" disabled> ESPReSSo</li>
<li class="task-list-item"><input type="checkbox" disabled> NIR illumination</li>
<li class="task-list-item"><input type="checkbox" disabled> Hysteresis filter</li>
<li class="task-list-item"><input type="checkbox" disabled> NVENC &#x26; NVDEC</li>
<li class="task-list-item"><input type="checkbox" disabled> TSDF depth gradient weighting</li>
<li class="task-list-item"><input type="checkbox" disabled> <a href="http://www.code-spot.co.za/2011/01/24/2d-minimum-and-maximum-filters-algorithms-and-implementation-issues/">2D min/max filter</a></li>
<li class="task-list-item"><input type="checkbox" disabled> Bisection search</li>
<li class="task-list-item"><input type="checkbox" disabled> Relief texture mapping</li>
<li class="task-list-item"><input type="checkbox" disabled> <a href="https://developer.nvidia.com/gpugems/gpugems/part-ii-lighting-and-shadows/chapter-11-shadow-map-antialiasing">Percentage closer filter</a></li>
<li class="task-list-item"><input type="checkbox" disabled> Squared cosine of angle between surface normal and camera vector</li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#hci" title="HCI">HCI</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#todo" title="TODO">TODO</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#setup" title="Setup">Setup</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#todo-1" title="TODO">TODO</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#implementation" title="Implementation">Implementation</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#lighting" title="Lighting">Lighting</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#calibration" title="Calibration">Calibration</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#capture" title="Capture">Capture</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#3d-face-tracking" title="3D Face Tracking">3D Face Tracking</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#compression-and-transmission" title="Compression and transmission">Compression and transmission</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#rendering" title="Rendering">Rendering</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#traditional-surface-fusion" title="Traditional Surface fusion">Traditional Surface fusion</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#novel-raycast-approach" title="Novel raycast approach">Novel raycast approach</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#weighted-color-blending" title="Weighted color blending">Weighted color blending</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#audio" title="Audio">Audio</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#todo-2" title="TODO">TODO</a></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"e9ow9c6apojiqfio5e5ceht","title":"Project Starline A high-fidelity telepresence system","desc":"","updated":1657885551467,"created":1657801332149,"custom":{},"fname":"paper-read.project-starline","type":"note","vault":{"fsPath":"vault"},"contentHash":"226bd5d87b2dbbc2da4d2f0cef7776c1","links":[{"type":"wiki","from":{"fname":"paper-read.project-starline","id":"e9ow9c6apojiqfio5e5ceht","vaultName":"vault"},"value":"epipolar-geometry.tsdf","alias":"epipolar-geometry.tsdf","position":{"start":{"line":64,"column":24,"offset":2537},"end":{"line":64,"column":50,"offset":2563},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"epipolar-geometry.tsdf"}}],"anchors":{"hci":{"type":"header","text":"HCI","value":"hci","line":10,"column":0,"depth":2},"todo":{"type":"header","text":"TODO","value":"todo","line":19,"column":0,"depth":3},"setup":{"type":"header","text":"Setup","value":"setup","line":26,"column":0,"depth":2},"todo-1":{"type":"header","text":"TODO","value":"todo-1","line":31,"column":0,"depth":3},"implementation":{"type":"header","text":"Implementation","value":"implementation","line":35,"column":0,"depth":2},"lighting":{"type":"header","text":"Lighting","value":"lighting","line":37,"column":0,"depth":3},"calibration":{"type":"header","text":"Calibration","value":"calibration","line":43,"column":0,"depth":3},"capture":{"type":"header","text":"Capture","value":"capture","line":47,"column":0,"depth":3},"3d-face-tracking":{"type":"header","text":"3D Face Tracking","value":"3d-face-tracking","line":53,"column":0,"depth":3},"compression-and-transmission":{"type":"header","text":"Compression and transmission","value":"compression-and-transmission","line":59,"column":0,"depth":3},"rendering":{"type":"header","text":"Rendering","value":"rendering","line":64,"column":0,"depth":3},"traditional-surface-fusion":{"type":"header","text":"Traditional Surface fusion","value":"traditional-surface-fusion","line":69,"column":0,"depth":4},"novel-raycast-approach":{"type":"header","text":"Novel raycast approach","value":"novel-raycast-approach","line":73,"column":0,"depth":4},"weighted-color-blending":{"type":"header","text":"Weighted color blending","value":"weighted-color-blending","line":78,"column":0,"depth":4},"audio":{"type":"header","text":"Audio","value":"audio","line":83,"column":0,"depth":3},"todo-2":{"type":"header","text":"TODO","value":"todo-2","line":86,"column":0,"depth":3}},"children":[],"parent":"2vmt81onv3jf06ejwfusj30","data":{}},"body":"\u003ch1 id=\"project-starline-a-high-fidelity-telepresence-system\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#project-starline-a-high-fidelity-telepresence-system\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eProject Starline A high-fidelity telepresence system\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003ca href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/3696afb4c1cccbe0876a9fedd1586f0f9c84f737.pdf\"\u003ehttps://storage.googleapis.com/pub-tools-public-publication-data/pdf/3696afb4c1cccbe0876a9fedd1586f0f9c84f737.pdf\u003c/a\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"hci\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#hci\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eHCI\u003c/h2\u003e\n\u003cp\u003eVR, AR: hard to capture under headset, insufficient pixel density and viewport\u003c/p\u003e\n\u003cp\u003eautostereoscopic display (65-inch 8K 33.1M pixel 60Hz, 1.25m eye-to-eye distance, 45 pixel per degree)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFace near display panel (reduce disparity)\u003c/li\u003e\n\u003cli\u003ePlace middle wall to block bottom of display (reduce depth conflicts)\u003c/li\u003e\n\u003cli\u003eMatching remote to local transform for both sides (ensure mutual eye contact)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"todo\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#todo\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eTODO\u003c/h3\u003e\n\u003cul class=\"contains-task-list\"\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e crosstalk\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e vergence-accommodation conflict\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e disparity\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e depth conflicts\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e mutual eye contact\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"setup\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#setup\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eSetup\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e4 tracking cameras (2 above, 2 side): localized eyes, ears, mouth, 120Hz\u003c/li\u003e\n\u003cli\u003e3 depth (stereo) camera: depth stream, 180Hz -\u003e image-based depth fusion\u003c/li\u003e\n\u003cli\u003e4 color camera: color stream, 60Hz -\u003e Normal based texture blending\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"todo-1\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#todo-1\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eTODO\u003c/h3\u003e\n\u003cul class=\"contains-task-list\"\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e HRTF (head-related transfer function)\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Normal based texture blending\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"implementation\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#implementation\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eImplementation\u003c/h2\u003e\n\u003ch3 id=\"lighting\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#lighting\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eLighting\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIBL (Image-based rendering), no illumination or reflectance\u003c/li\u003e\n\u003cli\u003eInterpolates textures from 4 color cameras\u003c/li\u003e\n\u003cli\u003eNon-Lambertian reflectance rander incorrectly under non-diffuse lighting (mitigated using soft lighting)\u003c/li\u003e\n\u003cli\u003eillumination nonuniformity (stronger intensities for display unit near wall)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"calibration\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#calibration\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCalibration\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMinimizing reprojection error over planar targets\u003c/li\u003e\n\u003cli\u003eColor calibration to Illuminant D65 (gain, color correction matrix, gamma)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"capture\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#capture\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCapture\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCapture sensor placed at periphery of the display, large parallax\u003c/li\u003e\n\u003cli\u003eNear-infrared (NIR) global shutter image sensors\u003c/li\u003e\n\u003cli\u003eCustomized depth sensor with near depth continuities\u003c/li\u003e\n\u003cli\u003e3 types of NIR illumination (NIR bounce light, NIR spot light, illuminate back wall)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"3d-face-tracking\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#3d-face-tracking\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e3D Face Tracking\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eEye location -\u003e stereo rendering\u003c/li\u003e\n\u003cli\u003eMouth \u0026#x26; ear location -\u003e spatial audio rendering + crosstalk cancellation\u003c/li\u003e\n\u003cli\u003e34 facial landmarks, determine 5 2D features (eyes, mouth, ears) and triangulated into 3D\u003c/li\u003e\n\u003cli\u003eLatency causes crosstalk, mitigated by extrapolation + double exponential smoothing + hysteresis filter\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"compression-and-transmission\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#compression-and-transmission\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCompression and transmission\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eTransmit color (8 bit) and depth (10 bit) images via video compression (NVENC/NVDEC unit, H.256 codec, YUV420 chroma subsampling)\u003c/li\u003e\n\u003cli\u003eClamp depth to reduce quantization artifacts\u003c/li\u003e\n\u003cli\u003eTransmit via WebRTC\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"rendering\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#rendering\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eRendering\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eCompute shadow map from color cameras by raycasting on input depth map\u003c/li\u003e\n\u003cli\u003eCompute user view output depth maps by raycasting on input depth map\u003c/li\u003e\n\u003cli\u003eUse shadow map to weighted color blend output depth map\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"traditional-surface-fusion\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#traditional-surface-fusion\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eTraditional Surface fusion\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eFuse depth view into \u003ca href=\"/my-personal-knowledge-cache/notes/r8y2bovxrlx6vkhn7my8e0m\"\u003eTSDF\u003c/a\u003e as volumetric grid, weighting depth pixel based on depth gradient\u003c/li\u003e\n\u003cli\u003eMarch along rays into precomputed voxel grid, find root (iso surface)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"novel-raycast-approach\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#novel-raycast-approach\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eNovel raycast approach\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eRasterizing input depth view to low-res output view, find lower/upper bound of distance along the ray using 2D min/max filter, dilate it with small margin\u003c/li\u003e\n\u003cli\u003eFor any point on user view ray, for each depth images, transform point to depth camera view coordinate, sample depth and fusion weight\u003c/li\u003e\n\u003cli\u003eFusion weight is inverse proportional to depth standard deviation over 7x7 pixel neighbourhood (0 if point is outside viewport)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"weighted-color-blending\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#weighted-color-blending\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eWeighted color blending\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eCompute partial visibility using percentage close filter on shadow map\u003c/li\u003e\n\u003cli\u003eModulate blend weight by squared cosine of angle between surface normal and camera vector (?)\u003c/li\u003e\n\u003cli\u003eAdaptively blur composite image along depth discontinuities (Edge blending)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"audio\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#audio\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eAudio\u003c/h3\u003e\n\u003cp\u003e[skip for now]\u003c/p\u003e\n\u003ch3 id=\"todo-2\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#todo-2\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eTODO\u003c/h3\u003e\n\u003cul class=\"contains-task-list\"\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Non-Lambertian reflectance\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Non-diffuse lighting\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Lighting ratio\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Non-planar warp\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e ESPReSSo\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e NIR illumination\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Hysteresis filter\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e NVENC \u0026#x26; NVDEC\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e TSDF depth gradient weighting\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e \u003ca href=\"http://www.code-spot.co.za/2011/01/24/2d-minimum-and-maximum-filters-algorithms-and-implementation-issues/\"\u003e2D min/max filter\u003c/a\u003e\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Bisection search\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Relief texture mapping\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e \u003ca href=\"https://developer.nvidia.com/gpugems/gpugems/part-ii-lighting-and-shadows/chapter-11-shadow-map-antialiasing\"\u003ePercentage closer filter\u003c/a\u003e\u003c/li\u003e\n\u003cli class=\"task-list-item\"\u003e\u003cinput type=\"checkbox\" disabled\u003e Squared cosine of angle between surface normal and camera vector\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"o3PkEany5FTDLokev2jkJ","title":"Root","desc":"","updated":1656832289330,"created":1640014633146,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"1f4a8dbd787743b10f24422968be02a9","links":[],"anchors":{"history":{"type":"header","text":"History","value":"history","line":10,"column":0,"depth":2},"disclaimer":{"type":"header","text":"Disclaimer","value":"disclaimer","line":15,"column":0,"depth":2}},"children":["Vn1Ykq4aIagi0bhZowkgD","ja5HFaIxVEtbZoTklNXfZ","vnzxfoqb6aqbrqy247uonqo","jjlv4wd30bvf0r680o9ptbi","kok8aerdrzko8v4i6w6qtjx","hr8ruqfxd2miwldyehzz5zy","criy8usqjrguecufwb3k8z2","3x9f9wclumzxc23dzgraepy","sma2hkp8hvq9urmtk94qqwq","4bcvwahaynsox941d8dimxw","8u19znq05xj50ptse0fq8nj","hbcft05imtwxxtwk52nij1n","2vmt81onv3jf06ejwfusj30","npuhs4xvm0sa31rz2gcuff3","mwt2mrjm58oa3q2osoqwd64","yjnf5fuac95jbdmjj923hyh","17p3nbv4rvga83hhsz2idzp","8r1egy8mz3lp7ud9p8kcg8z","5gf8xb68r1y0kxumkvvmuez","d92qhaqtfbt7e4eximdnbht","r25bm5nuug9krur6ddqearm"],"parent":null,"data":{},"body":"\nMy personal knowledge cache using [Dendron](https://www.dendron.so)\n\n## History\nIt was during my first job, at the start-up company called PixelShift.AI, that I acquired most prominent skill as a software engineer-the ability to read source code. It opened up a new way of learning and my knowledge expanded rapidly ever since. Learning new things is thriving but noting them down cogently and organized is hard. I often found myself forget the context few month later, making the notes completely intelligible. Additionally, some notes need frequent update as my previous understanding could be parochial, antiquated or even erroneous.\n\nIn desperate attempt to facilitate the noting/updating experience, I came across [Dendron](https://www.dendron.so) and found it surprisingly congenial to my personal need. With it, I have gradually grown the habit of caching, linking back and extending my knowledge base.\n\n## Disclaimer\nThe notes are collections of information I found along the journey. I use backquote to denote sources, but I am likely to miss some references, so apology in advance. Also, they are my personal understandings, usually added when I first encounter the topic and will be updated only when I come across it again, so some of them could be incomplete or wrong."},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.86.1","enableFullHierarchyNoteTitle":false,"enableHandlebarTemplates":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enablePrettyLinks":true,"assetsPrefix":"/my-personal-knowledge-cache","siteUrl":"https://ankbzpx.github.io","enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"e9ow9c6apojiqfio5e5ceht"},"buildId":"ihOclfcI71GY0CxNfF2GS","assetPrefix":"/my-personal-knowledge-cache","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>