{"pageProps":{"note":{"id":"e9ow9c6apojiqfio5e5ceht","title":"Project Starline A high-fidelity telepresence system","desc":"","updated":1657885551467,"created":1657801332149,"custom":{},"fname":"paper-read.project-starline","type":"note","vault":{"fsPath":"vault"},"contentHash":"226bd5d87b2dbbc2da4d2f0cef7776c1","links":[{"type":"wiki","from":{"fname":"paper-read.project-starline","id":"e9ow9c6apojiqfio5e5ceht","vaultName":"vault"},"value":"epipolar-geometry.tsdf","alias":"epipolar-geometry.tsdf","position":{"start":{"line":64,"column":24,"offset":2537},"end":{"line":64,"column":50,"offset":2563},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"epipolar-geometry.tsdf"}}],"anchors":{"hci":{"type":"header","text":"HCI","value":"hci","line":10,"column":0,"depth":2},"todo":{"type":"header","text":"TODO","value":"todo","line":19,"column":0,"depth":3},"setup":{"type":"header","text":"Setup","value":"setup","line":26,"column":0,"depth":2},"todo-1":{"type":"header","text":"TODO","value":"todo-1","line":31,"column":0,"depth":3},"implementation":{"type":"header","text":"Implementation","value":"implementation","line":35,"column":0,"depth":2},"lighting":{"type":"header","text":"Lighting","value":"lighting","line":37,"column":0,"depth":3},"calibration":{"type":"header","text":"Calibration","value":"calibration","line":43,"column":0,"depth":3},"capture":{"type":"header","text":"Capture","value":"capture","line":47,"column":0,"depth":3},"3d-face-tracking":{"type":"header","text":"3D Face Tracking","value":"3d-face-tracking","line":53,"column":0,"depth":3},"compression-and-transmission":{"type":"header","text":"Compression and transmission","value":"compression-and-transmission","line":59,"column":0,"depth":3},"rendering":{"type":"header","text":"Rendering","value":"rendering","line":64,"column":0,"depth":3},"traditional-surface-fusion":{"type":"header","text":"Traditional Surface fusion","value":"traditional-surface-fusion","line":69,"column":0,"depth":4},"novel-raycast-approach":{"type":"header","text":"Novel raycast approach","value":"novel-raycast-approach","line":73,"column":0,"depth":4},"weighted-color-blending":{"type":"header","text":"Weighted color blending","value":"weighted-color-blending","line":78,"column":0,"depth":4},"audio":{"type":"header","text":"Audio","value":"audio","line":83,"column":0,"depth":3},"todo-2":{"type":"header","text":"TODO","value":"todo-2","line":86,"column":0,"depth":3}},"children":[],"parent":"2vmt81onv3jf06ejwfusj30","data":{}},"body":"<h1 id=\"project-starline-a-high-fidelity-telepresence-system\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#project-starline-a-high-fidelity-telepresence-system\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Project Starline A high-fidelity telepresence system</h1>\n<blockquote>\n<p><a href=\"https://storage.googleapis.com/pub-tools-public-publication-data/pdf/3696afb4c1cccbe0876a9fedd1586f0f9c84f737.pdf\">https://storage.googleapis.com/pub-tools-public-publication-data/pdf/3696afb4c1cccbe0876a9fedd1586f0f9c84f737.pdf</a></p>\n</blockquote>\n<h2 id=\"hci\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#hci\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>HCI</h2>\n<p>VR, AR: hard to capture under headset, insufficient pixel density and viewport</p>\n<p>autostereoscopic display (65-inch 8K 33.1M pixel 60Hz, 1.25m eye-to-eye distance, 45 pixel per degree)</p>\n<ul>\n<li>Face near display panel (reduce disparity)</li>\n<li>Place middle wall to block bottom of display (reduce depth conflicts)</li>\n<li>Matching remote to local transform for both sides (ensure mutual eye contact)</li>\n</ul>\n<h3 id=\"todo\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#todo\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>TODO</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> crosstalk</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> vergence-accommodation conflict</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> disparity</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> depth conflicts</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> mutual eye contact</li>\n</ul>\n<h2 id=\"setup\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#setup\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Setup</h2>\n<ul>\n<li>4 tracking cameras (2 above, 2 side): localized eyes, ears, mouth, 120Hz</li>\n<li>3 depth (stereo) camera: depth stream, 180Hz -> image-based depth fusion</li>\n<li>4 color camera: color stream, 60Hz -> Normal based texture blending</li>\n</ul>\n<h3 id=\"todo-1\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#todo-1\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>TODO</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> HRTF (head-related transfer function)</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Normal based texture blending</li>\n</ul>\n<h2 id=\"implementation\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#implementation\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Implementation</h2>\n<h3 id=\"lighting\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#lighting\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Lighting</h3>\n<ul>\n<li>IBL (Image-based rendering), no illumination or reflectance</li>\n<li>Interpolates textures from 4 color cameras</li>\n<li>Non-Lambertian reflectance rander incorrectly under non-diffuse lighting (mitigated using soft lighting)</li>\n<li>illumination nonuniformity (stronger intensities for display unit near wall)</li>\n</ul>\n<h3 id=\"calibration\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#calibration\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Calibration</h3>\n<ul>\n<li>Minimizing reprojection error over planar targets</li>\n<li>Color calibration to Illuminant D65 (gain, color correction matrix, gamma)</li>\n</ul>\n<h3 id=\"capture\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#capture\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Capture</h3>\n<ul>\n<li>Capture sensor placed at periphery of the display, large parallax</li>\n<li>Near-infrared (NIR) global shutter image sensors</li>\n<li>Customized depth sensor with near depth continuities</li>\n<li>3 types of NIR illumination (NIR bounce light, NIR spot light, illuminate back wall)</li>\n</ul>\n<h3 id=\"3d-face-tracking\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#3d-face-tracking\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>3D Face Tracking</h3>\n<ul>\n<li>Eye location -> stereo rendering</li>\n<li>Mouth &#x26; ear location -> spatial audio rendering + crosstalk cancellation</li>\n<li>34 facial landmarks, determine 5 2D features (eyes, mouth, ears) and triangulated into 3D</li>\n<li>Latency causes crosstalk, mitigated by extrapolation + double exponential smoothing + hysteresis filter</li>\n</ul>\n<h3 id=\"compression-and-transmission\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#compression-and-transmission\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Compression and transmission</h3>\n<ul>\n<li>Transmit color (8 bit) and depth (10 bit) images via video compression (NVENC/NVDEC unit, H.256 codec, YUV420 chroma subsampling)</li>\n<li>Clamp depth to reduce quantization artifacts</li>\n<li>Transmit via WebRTC</li>\n</ul>\n<h3 id=\"rendering\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#rendering\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Rendering</h3>\n<ul>\n<li>Compute shadow map from color cameras by raycasting on input depth map</li>\n<li>Compute user view output depth maps by raycasting on input depth map</li>\n<li>Use shadow map to weighted color blend output depth map</li>\n</ul>\n<h4 id=\"traditional-surface-fusion\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#traditional-surface-fusion\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Traditional Surface fusion</h4>\n<ul>\n<li>Fuse depth view into <a href=\"/my-personal-knowledge-cache/notes/r8y2bovxrlx6vkhn7my8e0m\">TSDF</a> as volumetric grid, weighting depth pixel based on depth gradient</li>\n<li>March along rays into precomputed voxel grid, find root (iso surface)</li>\n</ul>\n<h4 id=\"novel-raycast-approach\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#novel-raycast-approach\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Novel raycast approach</h4>\n<ul>\n<li>Rasterizing input depth view to low-res output view, find lower/upper bound of distance along the ray using 2D min/max filter, dilate it with small margin</li>\n<li>For any point on user view ray, for each depth images, transform point to depth camera view coordinate, sample depth and fusion weight</li>\n<li>Fusion weight is inverse proportional to depth standard deviation over 7x7 pixel neighbourhood (0 if point is outside viewport)</li>\n</ul>\n<h4 id=\"weighted-color-blending\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#weighted-color-blending\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Weighted color blending</h4>\n<ul>\n<li>Compute partial visibility using percentage close filter on shadow map</li>\n<li>Modulate blend weight by squared cosine of angle between surface normal and camera vector (?)</li>\n<li>Adaptively blur composite image along depth discontinuities (Edge blending)</li>\n</ul>\n<h3 id=\"audio\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#audio\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>Audio</h3>\n<p>[skip for now]</p>\n<h3 id=\"todo-2\"><a aria-hidden=\"true\" class=\"anchor-heading\" href=\"#todo-2\"><svg aria-hidden=\"true\" viewBox=\"0 0 16 16\"><use xlink:href=\"#svg-link\"></use></svg></a>TODO</h3>\n<ul class=\"contains-task-list\">\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Non-Lambertian reflectance</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Non-diffuse lighting</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Lighting ratio</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Non-planar warp</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> ESPReSSo</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> NIR illumination</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Hysteresis filter</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> NVENC &#x26; NVDEC</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> TSDF depth gradient weighting</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"http://www.code-spot.co.za/2011/01/24/2d-minimum-and-maximum-filters-algorithms-and-implementation-issues/\">2D min/max filter</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Bisection search</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Relief texture mapping</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> <a href=\"https://developer.nvidia.com/gpugems/gpugems/part-ii-lighting-and-shadows/chapter-11-shadow-map-antialiasing\">Percentage closer filter</a></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Squared cosine of angle between surface normal and camera vector</li>\n</ul>","noteIndex":{"id":"o3PkEany5FTDLokev2jkJ","title":"Root","desc":"","updated":1656832289330,"created":1640014633146,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":"vault"},"contentHash":"1f4a8dbd787743b10f24422968be02a9","links":[],"anchors":{"history":{"type":"header","text":"History","value":"history","line":10,"column":0,"depth":2},"disclaimer":{"type":"header","text":"Disclaimer","value":"disclaimer","line":15,"column":0,"depth":2}},"children":["Vn1Ykq4aIagi0bhZowkgD","ja5HFaIxVEtbZoTklNXfZ","vnzxfoqb6aqbrqy247uonqo","jjlv4wd30bvf0r680o9ptbi","kok8aerdrzko8v4i6w6qtjx","hr8ruqfxd2miwldyehzz5zy","criy8usqjrguecufwb3k8z2","3x9f9wclumzxc23dzgraepy","sma2hkp8hvq9urmtk94qqwq","4bcvwahaynsox941d8dimxw","8u19znq05xj50ptse0fq8nj","hbcft05imtwxxtwk52nij1n","2vmt81onv3jf06ejwfusj30","npuhs4xvm0sa31rz2gcuff3","mwt2mrjm58oa3q2osoqwd64","yjnf5fuac95jbdmjj923hyh","17p3nbv4rvga83hhsz2idzp","8r1egy8mz3lp7ud9p8kcg8z","5gf8xb68r1y0kxumkvvmuez","d92qhaqtfbt7e4eximdnbht","r25bm5nuug9krur6ddqearm"],"parent":null,"data":{},"body":"\nMy personal knowledge cache using [Dendron](https://www.dendron.so)\n\n## History\nIt was during my first job, at the start-up company called PixelShift.AI, that I acquired most prominent skill as a software engineer-the ability to read source code. It opened up a new way of learning and my knowledge expanded rapidly ever since. Learning new things is thriving but noting them down cogently and organized is hard. I often found myself forget the context few month later, making the notes completely intelligible. Additionally, some notes need frequent update as my previous understanding could be parochial, antiquated or even erroneous.\n\nIn desperate attempt to facilitate the noting/updating experience, I came across [Dendron](https://www.dendron.so) and found it surprisingly congenial to my personal need. With it, I have gradually grown the habit of caching, linking back and extending my knowledge base.\n\n## Disclaimer\nThe notes are collections of information I found along the journey. I use backquote to denote sources, but I am likely to miss some references, so apology in advance. Also, they are my personal understandings, usually added when I first encounter the topic and will be updated only when I come across it again, so some of them could be incomplete or wrong."},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"randomNote":{},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"dendronVersion":"0.86.1","enableFullHierarchyNoteTitle":false,"enableHandlebarTemplates":false,"templateHierarchy":"template"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false,"enableFrontmatterTags":true,"enableHashesForFMTags":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"enableSiteLastModified":true,"siteRootDir":"docs","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"duplicateNoteBehavior":{"action":"useVault","payload":["vault"]},"writeStubs":false,"seo":{"title":"Dendron","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enablePrettyLinks":true,"assetsPrefix":"/my-personal-knowledge-cache","siteUrl":"https://ankbzpx.github.io","enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true}